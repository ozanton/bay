# bay portfolio
Data engeneering projects:
| Project | Description | Instruments |
| :---------------------- | :---------------------- | :---------------------- |
| [Obtaining data from sources](/API/) | Getting current weather data from weatherapi.com API and receiving forecast weather data from the windy.com API | *Python*, *DML*, *DDL*, *API* | 
|[Data load pipeline](/Data_load_pipeline/) | Automation of data collection and loading into the database. pipeline to separate logical tables and then build a data marts on them. Incremental data loading. | *Python*, *SQL*, *DML*, *DDL*, *Airflow*, *Pipeline*| 
| [ETL and data preparation automation](/ETL_data_preparation_automation/) | Creating a pipeline for incremental loading of data into the databas. | *Python*, *SQL*, *DML*, *DDL*, *Airflow*, *Pipeline*, *API* | 
| [Migrations project](/Migrations_project/) |  The task is to do a migration to separate logical tables and then build a datamart on them.  | *SQL*, *DML*, *DDL*, *Migrations*, *Backwards compatibility*| 
| [Analytical database](/Postgres_to_Clickchouse/)  |  Loading the data from Postgres, analytical database design, creating a data vault model in Clickhouse.  | *Python*, *PostgreSQL*, *Clickhouse*, *DML*, *DDL*, *Airflow*| 
| [Stream processing](/Kafka_Flink/) | Real-Time Stream Data Processing | *Kafka*, *Flink*, *SQL* | 
| [Analytical database](/S3_to_Vertica/) | Loading the data from S3, analytical database design, creating a data vault model. | *Boto3*, *SQL*, *DML*, *DDL*, *Airflow*, *Vertica*|
| [Streaming service](/Kafka/) | Getting the data from kafca topic, do some manipulations with data, saving to database and sending to another topic |*Kafka*, *SQL*| 
| [RFM analysis](/RFM/) | Creating a datamart for RFM classification of application users. | *SQL*, *DML*, *DDL*| 
| [DWH several sources](/DWH_several_sources/) | Creating a multilayer DWH and pipeline for incremental loading of data into the database. | *Python*, *SQL*, *DML*, *DDL*, *MongoDB*, *Airflow*, *API*| 
| [Data lake](/Data_Lake/) | Working with data in parquet format, calculating the metrics required by the business, creating data marts.| *Hadoop*, *Spark*, *Airflow*| 
| [Cloud service](/Cloud_service/) | Implementation of an application using microservice architecture. Data exchange between services using Kafka message broker.| *Kafka*, *PostgreSQL*, *Redis*, *Microservice*, *Kubernetes*, *Helm*, *Docker*| 

Data analitical (DA) projects:
| Project | Description | Instruments |
| :---------------------- | :---------------------- | :---------------------- |
| [Borrower relability research](/DA/borrower_reliability_research/) | Data preprocessing: Analysis of data on marital status and number of children of the client on the fact of repayment of the loan on time to build a credit scoring model.  | *pandas*| 
| [Realty reseaech](/DA/realty_research/) | Exploratory data analysis: Parameters for determining the market value of real estate. | *pandas*, *matplotlib*| 
| [Determining a prospective tariff for a telecom company](/DA/best_tariff_for_telecom_company/) | Statistical analysis of data: Finding out using statistical methods which communications company's tariff is the most profitable. | *pandas, numpy, math, matplotlib, scipy* | 
| [Computer games market analysis](/DA/games_market/) | Statistical analysis of data: Identifying patterns that determine the success of a game. | *pandas, matplotlib* | 
| [Analytics in the airline industry](/DA/airlines/) | Data Extraction: Downloading data from a SQL database and conducting exploratory data analysis. | *SQL, pandas, matplotlib* | 
| [.....](/DA/...../) | ..... | *.....*, *....*, *.....*, *.....* | 
